# Parsing Binary Files
# 解析二进制文件

[原文链接](https://github.com/antlr/antlr4/blob/master/doc/parsing-binary-files.md)

Parsing binary files is no different than parsing character-based files except that the "characters" are actually bytes not 16-bit unsigned short unicode characters.  From a lexer/parser point of view, there is no difference except that the characters are likely not printable.  If you want to match a special 2-byte marker 0xCA then 0xFE, the following rule is sufficient.
解析二进制文件与解析基于字符的文件没有什么不同，只是"字符"实际上是字节而不是 16 位无符号短 Unicode 字符。从词法分析器/解析器的角度来看，除了字符可能不可打印外，没有区别。如果您想匹配一个特殊的 2 字节标记 0xCA 然后 0xFE，以下规则就足够了。

```
MARKER : '\u00CA' '\u00FE' ;
```

The parser of course would refer to that token like any other token.
解析器当然会像引用任何其他词法符号一样引用该词法符号。

Here is a sample grammar for use with the code snippets below.
以下是与下面代码片段一起使用的示例语法。

```
grammar IP;

file : ip+ (MARKER ip)* ;

ip : BYTE BYTE BYTE BYTE ;

MARKER : '\u00CA' '\u00FE' ;
BYTE : '\u0000'..'\u00FF' ;
```

Notice that `BYTE` is using a range operator to match anything between 0 and 255. We can't use character classes like `[a-z]` naturally because we are not parsing character codes.  All character specifiers must have `00` as their upper byte. E.g., `\uCAFE` is not a valid character because that 16-bit value will never be created from the input stream (bytes only remember).
请注意，`BYTE` 使用范围运算符来匹配 0 到 255 之间的任何内容。我们自然不能使用像 `[a-z]` 这样的字符类，因为我们不是在解析字符代码。所有字符说明符必须将 `00` 作为其高字节。例如，`\uCAFE` 不是有效字符，因为该 16 位值永远不会从输入流中创建（字节只记住）。

If there are actual characters like `$` or `!` encoded as bytes in the binary file, you can refer to them via literals like `'$'` as you normally would. See `'.'` in the grammar.
如果二进制文件中有像 `$` 或 `!` 这样的实际字符被编码为字节，您可以像通常那样通过字面量如 `'$'` 来引用它们。请参见语法中的 `'.'`。

## Binary streams
## 二进制流

There are many targets now so I'm not sure exactly how they process text files but most targets will pull in text per the machine's locale. Much of the time this will mean UTF-8 encoding of text converted to 16-bit Unicode. ANTLR's lexers operate on `int` so we can handle any kind of character you want to send in that fits in `int`.
现在有很多目标，所以我不确定它们具体如何处理文本文件，但大多数目标会根据机器的区域设置拉入文本。很多时候，这将意味着将文本的 UTF-8 编码转换为 16 位 Unicode。ANTLR 的词法分析器操作的是 `int`，所以我们可以处理任何您想要发送的适合 `int` 的字符。

Once the lexer gets an input stream, it doesn't care whether the characters come from / represent bytes or actual Unicode characters.
一旦词法分析器获得输入流，它就不关心字符是来自/代表字节还是实际的 Unicode 字符。

Let's get a binary file called `ips` and put it in our resources directory:
让我们获取一个名为 `ips` 的二进制文件并将其放入我们的资源目录中：

```java
public class WriteBinaryFile {
	public static final byte[] bytes = {
		(byte)172, 0, 0, 1, (byte)0xCA, (byte)0xFE,
		(byte)10, 10, 10, 1, (byte)0xCA, (byte)0xFE,
		(byte)10, 10, 10, 99
	};

	public static void main(String[] args) throws IOException {
		Files.write(new File("/tmp/ips").toPath(), bytes);
	}
}
```

Now we need to create a stream of bytes satisfactory to ANTLR, which is as simple as:
现在我们需要创建一个让 ANTLR 满意的字节流，这很简单：

```java
CharStream bytesAsChar = CharStreams.fromFileName("/tmp/ips", StandardCharsets.ISO_8859_1);
```

The `ISO-8859-1` encoding is just the 8-bit char encoding for LATIN-1, which effectively tells the stream to treat each byte as a character. That's what we want. Then we have the usual test rig:
`ISO-8859-1` 编码只是 LATIN-1 的 8 位字符编码，它有效地告诉流将每个字节视为一个字符。这正是我们想要的。然后我们有了通常的测试装置：

```java
//ANTLRFileStream bytesAsChar = new ANTLRFileStream("/tmp/ips", "ISO-8859-1"); DEPRECATED in 4.7
CharStream bytesAsChar = CharStreams.fromFileName("/tmp/ips", StandardCharsets.ISO_8859_1);
IPLexer lexer = new IPLexer(bytesAsChar);
CommonTokenStream tokens = new CommonTokenStream(lexer);
IPParser parser = new IPParser(tokens);
ParseTree tree = parser.file();
IPBaseListener listener = new MyIPListener();
ParseTreeWalker.DEFAULT.walk(listener, tree);
```

Here is the listener:
这是监听器：

```java
class MyIPListener extends IPBaseListener {
	@Override
	public void exitIp(IPParser.IpContext ctx) {
		List<TerminalNode> octets = ctx.BYTE();
		short[] ip = new short[4];
		for (int i = 0; i<octets.size(); i++) {
			String oneCharStringHoldingOctet = octets.get(i).getText();
			ip[i] = (short)oneCharStringHoldingOctet.charAt(0);
		}
		System.out.println(Arrays.toString(ip));
	}
}
```

We can't just print out the text because we are not reading in text. We need to emit each byte as a decimal value. The output should be the following when you run the test code:
我们不能直接打印文本，因为我们不是在读取文本。我们需要将每个字节作为十进制值发出。当您运行测试代码时，输出应该是以下内容：

```
[172, 0, 0, 1]
[10, 10, 10, 1]
[10, 10, 10, 99]
```

## Custom stream
## 自定义流

(*ANTLRFileStream was deprecated in 4.7*)
（*ANTLRFileStream 在 4.7 中已弃用*）

If you want to play around with the stream, you can. Here's an example that alters how "text" is computed from the byte stream (which changes how tokens print out their text as well):
如果您想对流进行一些操作，可以。以下是一个更改从字节流计算"文本"方式的示例（这也改变了词法符号打印其文本的方式）：

```java
/** make a stream treating file as full of single unsigned byte characters */
class BinaryANTLRFileStream extends ANTLRFileStream {
	public BinaryANTLRFileStream(String fileName) throws IOException {
		super(fileName, "ISO-8859-1");
	}

	/** Print the decimal value rather than treat as char */
	@Override
	public String getText(Interval interval) {
		StringBuilder buf = new StringBuilder();
		int start = interval.a;
		int stop = interval.b;
		if(stop >= this.n) {
			stop = this.n - 1;
		}

		for (int i = start; i<=stop; i++) {
			int v = data[i];
			buf.append(v);
		}
		return buf.toString();
	}
}
```

The new test code starts out like this:
新的测试代码开始如下：

```java
ANTLRFileStream bytesAsChar = new BinaryANTLRFileStream("/tmp/ips");
IPLexer lexer = new IPLexer(bytesAsChar);
...
```

This simplifies our listener then:
这简化了我们的监听器：

```java
class MyIPListenerCustomStream extends IPBaseListener {
	@Override
	public void exitIp(IPParser.IpContext ctx) {
		List<TerminalNode> octets = ctx.BYTE();
		System.out.println(octets);
	}
}
```

You should get this enhanced output:
您应该得到这个增强的输出：

```
[172(0xAC), 0(0x0), 0(0x0), 1(0x1)]
[10(0xA), 10(0xA), 10(0xA), 1(0x1)]
[10(0xA), 10(0xA), 10(0xA), 99(0x63)]
```

## Error handling in binary files
## 二进制文件中的错误处理

Error handling proceeds exactly like any other parser. For example, let's alter the binary file so that it is missing one of the 0's in the first IP address:
错误处理与任何其他解析器完全相同。例如，让我们修改二进制文件，使其在第一个 IP 地址中缺少一个 0：

```java
public static final byte[] bytes = {
	(byte)172, 0, 1, (byte)0xCA, (byte)0xFE, // OOOPS
	(byte)10, 10, 10, 1, (byte)0xCA, (byte)0xFE,
	(byte)10, 10, 10, 99
};
```

Running the original test case gives us:
运行原始测试用例给我们：

```
line 1:4 extraneous input '.' expecting BYTE
line 1:6 mismatched input 'Êþ' expecting '.'
[172, 0, 1, 0]
[10, 10, 10, 1]
[10, 10, 10, 99]
```

That `'Êþ'` is just to the character representation of two bytes 0xCA and 0xFE. Using the enhanced binary stream, we see:
那个 `'Êþ'` 只是两个字节 0xCA 和 0xFE 的字符表示。使用增强的二进制流，我们看到：

```
line 1:4 extraneous input '46(0x2E)' expecting BYTE
line 1:6 mismatched input '202(0xCA)254(0xFE)' expecting '.'
[172(0xAC), 0(0x0), 1(0x1)]
[10(0xA), 10(0xA), 10(0xA), 1(0x1)]
[10(0xA), 10(0xA), 10(0xA), 99(0x63)]
```
