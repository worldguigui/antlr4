# Parser and Lexer Interpreters
# 解析器和词法分析器解释器

[原文链接](https://github.com/antlr/antlr4/blob/master/doc/interpreters.md)

*Since ANTLR 4.2*
*自 ANTLR 4.2 起*

For small parsing tasks it is sometimes convenient to use ANTLR in interpreted mode, rather than generating a parser in a particular target, compiling it and running it as part of your application. Here's some sample code that creates lexer and parser Grammar objects and then creates interpreters. Once we have a ParserInterpreter, we can use it to parse starting in any rule we like, given a rule index (which the grammar + the parser can provide).
对于小型解析任务，有时使用 ANTLR 的解释模式比在特定目标中生成解析器、编译它并将其作为应用程序的一部分运行更方便。以下是一些示例代码，用于创建词法分析器和解析器语法对象，然后创建解释器。一旦我们有了 ParserInterpreter，我们可以使用它从我们喜欢的任何规则开始解析，给定一个规则索引（语法 + 解析器可以提供）。

## Action Code
## 动作代码

Since interpreters don't use generated parsers + lexers they cannot execute any action code (including predicates). That means the interpreter runs as if there were no predicates at all. If your grammar requires action code in order to parse correctly you will not be able to test it using this approach.
由于解释器不使用生成的解析器 + 词法分析器，它们无法执行任何动作代码（包括断言）。这意味着解释器运行时就像根本没有断言一样。如果您的语法需要动作代码才能正确解析，您将无法使用此方法测试它。

## Java Target Interpreter Setup
## Java 目标解释器设置

```java
LexerGrammar lg = new LexerGrammar(
    "lexer grammar L;\n" +
    "A : 'a' ;\n" +
    "B : 'b' ;\n" +
    "C : 'c' ;\n");
Grammar g = new Grammar(
    "parser grammar T;\n" +
    "s : (A|B)* C ;\n",
    lg);   
LexerInterpreter lexEngine =
    lg.createLexerInterpreter(new ANTLRInputStream(input));
CommonTokenStream tokens = new CommonTokenStream(lexEngine);
ParserInterpreter parser = g.createParserInterpreter(tokens);
ParseTree t = parser.parse(g.rules.get(startRule).index);
```

You can also load combined grammars from a file:
您也可以从文件加载组合语法：

```java
public static ParseTree parse(String fileName,
                              String combinedGrammarFileName,
                              String startRule)
    throws IOException
{
    final Grammar g = Grammar.load(combinedGrammarFileName);
    LexerInterpreter lexEngine = g.createLexerInterpreter(CharStreams.fromPath(Paths.get(fileName)));
    CommonTokenStream tokens = new CommonTokenStream(lexEngine);
    ParserInterpreter parser = g.createParserInterpreter(tokens);
    ParseTree t = parser.parse(g.getRule(startRule).index);
    System.out.println("parse tree: "+t.toStringTree(parser));
    return t;
}
```

Then:
然后：

```java
ParseTree t = parse("T.om",
                    MantraGrammar,
                    "compilationUnit");
```
 
To load separate lexer/parser grammars, do this:
要加载独立的词法分析器/解析器语法，请执行以下操作：

```java
public static ParseTree parse(String fileNameToParse,
                              String lexerGrammarFileName,
                              String parserGrammarFileName,
                              String startRule)
    throws IOException
{
    final LexerGrammar lg = (LexerGrammar) Grammar.load(lexerGrammarFileName);
    final Grammar pg = Grammar.load(parserGrammarFileName, lg);
    CharStream input = CharStreams.fromPath(Paths.get(fileNameToParse));
    LexerInterpreter lexEngine = lg.createLexerInterpreter(input);
    CommonTokenStream tokens = new CommonTokenStream(lexEngine);
    ParserInterpreter parser = pg.createParserInterpreter(tokens);
    ParseTree t = parser.parse(pg.getRule(startRule).index);
    System.out.println("parse tree: " + t.toStringTree(parser));
    return t;
}
```

Then:
然后：

```java
ParseTree t = parse(fileName, XMLLexerGrammar, XMLParserGrammar, "document");
```

This is also how we will integrate instantaneous parsing into ANTLRWorks2 and development environment plug-ins.
这也是我们将即时解析集成到 ANTLRWorks2 和开发环境插件中的方式。

See [TestParserInterpreter.java](../tool-testsuite/test/org/antlr/v4/test/tool/TestParserInterpreter.java).
参见 [TestParserInterpreter.java](../tool-testsuite/test/org/antlr/v4/test/tool/TestParserInterpreter.java)。

## Non-Java Target Interpreter Setup
## 非 Java 目标解释器设置
The ANTLR4 runtimes do not contain any grammar parsing classes (they are in the ANTLR4 tool  jar). Hence we cannot use `LexerGrammar` and `Grammar` to parse grammars for the interpreter. Instead we directly instantiate `LexerInterpreter` and `ParserInterpreter` objects. They require some data (namely symbol information and the ATNs) which only the ANTLR4 tool can give us. However, on each generation run ANTLR not only produces your parser + lexer files but also interpreter data files (*.interp) which contain all you need to feed the interpreters.
ANTLR4 运行时不包含任何语法解析类（它们在 ANTLR4 工具 jar 中）。因此，我们不能使用 `LexerGrammar` 和 `Grammar` 来为解释器解析语法。相反，我们直接实例化 `LexerInterpreter` 和 `ParserInterpreter` 对象。它们需要一些数据（即符号信息和 ATN），这些数据只有 ANTLR4 工具才能提供给我们。然而，在每次生成运行时，ANTLR 不仅生成您的解析器 + 词法分析器文件，还生成解释器数据文件（*.interp），其中包含您需要提供给解释器的所有内容。

A support class (`InterpreterDataReader`) is used to load the data for your convenience, which makes this very easy to use. Btw. even the Java target go this route instead of using the non-runtime classes `Grammar` and `LexerGrammar`. Sometimes it might not be feasible to use the tool jar for whatever reason.
为了方便起见，使用了一个支持类（`InterpreterDataReader`）来加载数据，这使得它非常易于使用。顺便说一句，即使是 Java 目标也采用这种方法，而不是使用非运行时类 `Grammar` 和 `LexerGrammar`。有时，无论出于何种原因，使用工具 jar 可能不可行。

Here's how the setup looks like (C++ example):
以下是设置的样子（C++ 示例）：

```cpp
/**
 * sourceFileName - name of the file with content to parse
 * lexerName - the name of your lexer (arbitrary, that's what is used in error messages)
 * parserName - ditto for the parser
 * lexerDataFileName - the lexer interpeter data file name (e.g. `<path>/ExprLexer.interp`)
 * parserDataFileName - ditto for the parser (e.g. `<path>/Expr.interp`)
 * startRule - the name of the rule to start parsing at
 */
void parse(std::string const& sourceFileName,
  std::string const& lexerName, std::string const& parserName,
  std::string const& lexerDataFileName, std::string const& parserDataFileName,
  std::string const& startRule) {
  
    InterpreterData lexerData = InterpreterDataReader::parseFile(lexerDataFileName);
    InterpreterData parserData = InterpreterDataReader::parseFile(parserDataFileName);

    ANTLRFileStream input(sourceFileName);
    LexerInterpreter lexEngine(lexerName, lexerData.vocabulary, lexerData.ruleNames,
      lexerData.channels, lexerData.modes, lexerData.atn, &input);
    CommonTokenStream tokens(&lexEngine);

    /* Remove comment to print the tokens.
    tokens.fill();
    std::cout << "INPUT:" << std::endl;
    for (auto token : tokens.getTokens()) {
      std::cout << token->toString() << std::endl;
    }
    */

    ParserInterpreter parser(parserName, parserData.vocabulary, parserData.ruleNames,
      parserData.atn, &tokens);
    tree::ParseTree *tree = parser.parse(parser.getRuleIndex(startRule));

    std::cout << "parse tree: " << tree->toStringTree(&parser) << std::endl;
}
```
